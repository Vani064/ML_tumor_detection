{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ndf = pd.read_csv('../input/braintumordetection/set.csv')\ndf.head()","metadata":{"id":"NAed1-9ThMgd","outputId":"18e0e1e1-938f-4b52-f514-972a7174a5e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"D6aOuaPwulId","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Count the number of rows and columns in the data set\ndf.shape\n","metadata":{"id":"ybPBv_LMhwk6","outputId":"0913b609-0320-4003-910a-bafa03fb0078","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize this count\nsns.countplot(df['Class'],label=\"Count\")","metadata":{"id":"pYRl85nPh_MA","outputId":"e197c1a8-9b89-4f78-f589-dcd659ea2c15","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Look at the data types to see which columns need to be transformed / encoded to a number\ndf.dtypes","metadata":{"id":"MKxSC619igYN","outputId":"faff76d4-6091-4c72-d65f-f9d6d6a84c8c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the correlation of the columns\ndf.corr()","metadata":{"id":"BrTd4-Czi6i1","outputId":"bb6eceeb-30ce-448c-ba88-d82db3910f33","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize the correlation \n#NOTE: To see the numbers within the cell ==>  sns.heatmap(df.corr(), annot=True)\nplt.figure(figsize=(20,10))  #This is used to change the size of the figure/ heatmap\nsns.heatmap(df.corr(), annot=True, fmt='.0%')\n#plt.figure(figsize=(10,10)) #This is used to change the size of the figure/ heatmap\n#sns.heatmap(df.iloc[:,1:12].corr(), annot=True, fmt='.0%') #Get a heap map of 11 columns, index 1-11, note index 0 is just the id column and is left out.","metadata":{"id":"Ql7bEQxmjDFR","outputId":"70654ac9-533a-4f59-efdd-1ae3cc0e6dfe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the data into independent 'X' and dependent 'Y' variables\nX = df.iloc[:, 0:8].values \nY = df.iloc[:, 9].values ","metadata":{"id":"t9JePsysjLSt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into 75% Training set and 25% Testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.29, random_state = 0)","metadata":{"id":"9YO6-hbbjRnQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n#X_train","metadata":{"id":"i0rniIGgkWMi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create a function within many Machine Learning Models\ndef models(X_train,Y_train):\n  \n  #Using Logistic Regression Algorithm to the Training Set\n  from sklearn.linear_model import LogisticRegression\n  log = LogisticRegression(random_state = 0)\n  log.fit(X_train, Y_train)\n  \n  #Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n  from sklearn.neighbors import KNeighborsClassifier\n  knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n  knn.fit(X_train, Y_train)\n\n  #Using SVC method of svm class to use Support Vector Machine Algorithm\n  from sklearn.svm import SVC\n  svc_lin = SVC(kernel = 'linear', random_state =0)\n  svc_lin.fit(X_train, Y_train)\n\n  #Using SVC method of svm class to use Kernel SVM Algorithm\n  from sklearn.svm import SVC\n  svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n  svc_rbf.fit(X_train, Y_train)\n\n  #Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\n  from sklearn.naive_bayes import GaussianNB\n  gauss = GaussianNB()\n  gauss.fit(X_train, Y_train)\n\n  #Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n  from sklearn.tree import DecisionTreeClassifier\n  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n  tree.fit(X_train, Y_train)\n\n  #Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n  from sklearn.ensemble import RandomForestClassifier\n  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 10)\n  forest.fit(X_train, Y_train)\n  \n  \n  #print model accuracy on the training data.\n  print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n  print('[1]K Nearest Neighbor Training Accuracy:', knn.score(X_train, Y_train))\n  print('[2]Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, Y_train))\n  print('[3]Support Vector Machine (RBF Classifier) Training Accuracy:', svc_rbf.score(X_train, Y_train))\n  print('[4]Gaussian Naive Bayes Training Accuracy:', gauss.score(X_train, Y_train))\n  print('[5]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))\n  print('[6]Random Forest Classifier Training Accuracy:', forest.score(X_train, Y_train))\n  \n  return log, knn, svc_lin, svc_rbf, gauss, tree, forest\n\nmodel = models(X_train,Y_train)","metadata":{"id":"IVZc9ygekZy7","outputId":"77d8e52d-e078-4a40-8e57-f202295fd116","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show the confusion matrix and accuracy for all of the models on the test data\n#Classification accuracy is the ratio of correct predictions to total predictions made.\nfrom sklearn.metrics import confusion_matrix\nfor i in range(len(model)):\n  cm = confusion_matrix(Y_test, model[i].predict(X_test))\n  TN = cm[0][0]\n  TP = cm[1][1]\n  FN = cm[1][0]\n  FP = cm[0][1]\n  print(cm)\n  print('Model[{}] Testing Accuracy = \"{}!\"'.format(i,  (TP + TN) / (TP + TN + FN + FP)))\n  print()# Print a new line\n\n#Show other ways to get the classification accuracy & other metrics \n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nfor i in range(len(model)):\n  print('Model ',i)\n  #Check precision, recall, f1-score\n  print( classification_report(Y_test, model[i].predict(X_test)) )\n  #Another way to get the models accuracy on the test data\n  print( accuracy_score(Y_test, model[i].predict(X_test)))\n  print()#Print a new line\n\n    \n#Print Prediction of Random Forest Classifier model\npred = model[6].predict(X_test)\nprint(pred)\n#Print a space\nprint()\n#Print the actual values\nprint(Y_test)\n","metadata":{"id":"0J_flLpJlN_5","outputId":"fc32483a-5f1c-4230-cf8a-b94f4114fc7c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Pp_cFyagoKC0","trusted":true},"execution_count":null,"outputs":[]}]}